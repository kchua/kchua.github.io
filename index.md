---
layout: default
title: Kurtland Chua
description: About Me
math: false
---

## About Me

<div>
  <div class="col" style="float: right;">
    <img class="prof-im" src="images/new-profile.jpg" style="display: block; width: 80%; margin: auto;"/>
  </div>
  <div>
    <p>
      I am currently a research scientist at Meta, where I am working on recommendation systems.
    </p>
    <p>
      Previously, I was a PhD student at Princeton University working on theoretical analyses of meta-learning, where I was advised by <a href="https://jasondlee88.github.io/">Jason D. Lee</a>.
      Before then, I studied EE/CS at UC Berkeley, where I worked on model-based reinforcement learning together with <a href="https://people.eecs.berkeley.edu/~svlevine/">Sergey Levine</a>, <a href="https://www.robertocalandra.com/about/">Roberto Calandra</a>, and <a href="https://rowanmcallister.github.io">Rowan McAllister</a>.
    </p>
  </div>
</div>

## Publications

* [Provable Hierarchy-Based Meta-Reinforcement Learning](https://arxiv.org/abs/2110.09507)  
  **Kurtland Chua**, Qi Lei, Jason D. Lee.  
  *AISTATS 2023.*

* [How Fine-Tuning Allows for Effective Meta-Learning.](https://arxiv.org/abs/2105.02221)  
  **Kurtland Chua**, Qi Lei, Jason D. Lee.  
  *NeurIPS 2021.*

* [On the Importance of Hyperparameter Optimization for Model-based Reinforcement Learning.](https://arxiv.org/abs/2102.13651)  
  Baohe Zhang, Raghu Rajan, Luis Pineda, Nathan Lambert, Andr√© Biedenkapp, **Kurtland Chua**, Frank Hutter, Roberto Calandra.  
  *AISTATS 2021.*

* [Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models.](https://arxiv.org/abs/1805.12114)  
  [website](https://sites.google.com/view/drl-in-a-handful-of-trials/home)  | [code](https://github.com/kchua/handful-of-trials)  
  **Kurtland Chua**, Roberto Calandra, Rowan McAllister, Sergey Levine.  
  *NeurIPS 2018 ([Spotlight presentation](https://youtu.be/6LuK72GCCnI?t=3483), ~4% of submitted papers).*  

## Talks

* "Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models." *Bay Area Machine Learning Symposium (Baylearn)*. October 2018.  
  [video](https://www.youtube.com/watch?v=pq8xNCETPHU)

## Teaching

* COS 435: Introduction to Reinforcement Learning, Princeton  
  *Assistant in Instruction*  
  [Spring 2024](https://ben-eysenbach.github.io/intro-rl/)

* COS 240: Reasoning about Computation, Princeton  
  *Assistant in Instruction*  
  [Fall 2023](https://www.cs.princeton.edu/courses/archive/fall23/cos240/index.html)

* EECS 126: Probability and Random Processes, UC Berkeley  
  *Undergraduate Student Instructor (uGSI)*  
  [Spring 2019](https://inst.eecs.berkeley.edu/~ee126/sp19/) | [Fall 2018](https://inst.eecs.berkeley.edu/~ee126/fa18/)

## Honors and Awards

* *National Science Foundation Graduate Research Fellowship (2019)*.
* *Gordon Y.S. Wu Fellowship in Engineering (2019)*.
* *EECS Major Citation (2019)*.
* *NVIDIA Pioneer Award (2018)*. Awarded for *Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models* at NeurIPS 2018.  
* *Phi Beta Kappa Honors Society (2018)*. Inducted as a junior.
